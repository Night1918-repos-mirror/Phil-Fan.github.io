# 00 | Math in ML


## Linear algebra

矩阵：Matrix
向量：Vector
转置：Transpose
共轭：Conjugate
导数：Gradient
转置共轭：Hermitian
求逆：Inverse
线性组合：Linear Combination 

线性无关：Linear Independece 
奇异性：Singular 
向量空间：Vector Space
内积：inner product
外积：outer product
范数： norm

概率密度函数：probabiity density function (pdf)
累计分布函数： cumulative distribution function (cdf)
均值向量：mean vector 
相关矩阵：correlation matrix
协方差矩阵：covariance matrix
自相关：auto-correlation
互相关：cross-correlation
二次型 ： quadratic form
行列式：determinant
特征值： eigenvalue
迹：trace
秩：rank
求逆：inverse


矩阵求逆引理：matrix inverse lemma
伪逆：pseudo inverse 
直和：direct sum
Hadamard积： Hadamard product 
Kronecker 积：Kronecker product 
稀疏：sparse 
压缩感知：compressive sensing 


Hermitian matrix
Permutation matrix
Communication matrix
Generalized permutation matrix 
Scale and permutation ambiguities 
Orthogonal matrix
Unitary matrix
Upper triangular matrix
Lower  triangular matrix 
LU decomposition 
Vandemonde matrix 
Similar matrix (with respect to eigenvalues/vectors -> the same determinant and trace)
### Vectors
#### Norm
[什么是范数（norm）？以及L1,L2范数的简单介绍\_l1 norm-CSDN博客](https://blog.csdn.net/qq_37466121/article/details/87855185)

#### Dot Product
#### rotate
#### Vector Projection

### 矩阵


#### determinant

#### trace

#### Rank

#### Tensors（todo）





#### inverse

#### Pseudo-Inverse（todo）



#### Matrix Norms

#### Hadamard product（todo）


### 矩阵分解
#### Eigen decomposition


#### SVD | Singular Value Decomposition（todo）


#### 矩阵求导


## Differential calculus
### Higher Order Derivatives

### Taylor Series

### Partial Derivatives


### Gradient

### Hessian Matrix

### Jacobian Matrix（todo）






## Probability
### Random variables
### Probability distributions
### Bayes’ Theorem（todo）

### 统计量
#### Expected Value
#### Variance
#### Covariance & Correlation

### Probability Distributions

## Information theory
### Entropy

### Kullback–Leibler Divergence（todo）

### Cross-entropy（todo）



## Optimization algorithms